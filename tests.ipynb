{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "def WarpImage_TPS(source, target, img):\n",
    "    tps = cv2.createThinPlateSplineShapeTransformer()\n",
    "        \n",
    "    source=source.reshape(-1,len(source),2)\n",
    "    target=target.reshape(-1,len(target),2)\n",
    "    \n",
    "    matches=list()\n",
    "    \n",
    "    for i in range(0,len(source[0])):\n",
    "        matches.append(cv2.DMatch(i,i,0))\n",
    "    \n",
    "    matches = sorted(matches, key=lambda x: x.distance)\n",
    "\n",
    "    tps.estimateTransformation(target, source, matches)\n",
    "    new_img = tps.warpImage(img)\n",
    "    \n",
    "    return new_img, matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "img1 = cv2.imread('./data/osim.jpg')\n",
    "mask = cv2.imread('./data/osim.png')\n",
    "clothes = cv2.imread('./data/align_shirt.png')\n",
    "\n",
    "clothes_gray = cv2.cvtColor(clothes, cv2.COLOR_BGR2GRAY)\n",
    "clothes_mask = cv2.threshold(clothes_gray, 0, 255, cv2.THRESH_BINARY)[1]\n",
    "cv2.imwrite('clothes_mask.png', clothes_mask)\n",
    "\n",
    "mask_ = cv2.cvtColor(mask, cv2.COLOR_BGR2GRAY)\n",
    "mask_contour, _ = cv2.findContours(mask_, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "mask_contour = mask_contour[0]\n",
    "mask_contour_sq = mask_contour.squeeze()\n",
    "\n",
    "clothes_mask_contour, _ = cv2.findContours(clothes_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "clothes_mask_contour = clothes_mask_contour[0]\n",
    "clothes_mask_contour_sq = clothes_mask_contour.squeeze()\n",
    "\n",
    "cv2.drawContours(mask, mask_contour, -1, (0, 255, 0), 2)\n",
    "cv2.drawContours(mask, clothes_mask_contour, -1, (0, 0, 255), 2)\n",
    "\n",
    "# Align the images using TPS warping\n",
    "img2_aligned, matches = WarpImage_TPS(mask_contour_sq, clothes_mask_contour_sq, clothes)\n",
    "\n",
    "visualize_matches(mask, mask_contour_sq, clothes, clothes_mask_contour_sq, matches)\n",
    "\n",
    "# Display the aligned image\n",
    "cv2.imshow('mask contour', mask)\n",
    "cv2.imshow('clothes mask contour', clothes)\n",
    "cv2.imshow('Aligned Image', img2_aligned)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(431, 2)"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clothes_mask_contour_sq.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def visualize_matches(img1, keypoints1, img2, keypoints2, matches):\n",
    "    # Create a new image to display the matches\n",
    "    height = max(img1.shape[0], img2.shape[0])\n",
    "    width = img1.shape[1] + img2.shape[1]\n",
    "    img_matches = np.zeros((height, width, 3), dtype=np.uint8)\n",
    "\n",
    "    # Concatenate the two input images horizontally\n",
    "    img_matches[:img1.shape[0], :img1.shape[1]] = img1\n",
    "    img_matches[:img2.shape[0], img1.shape[1]:] = img2\n",
    "\n",
    "    # Draw lines between the matching keypoints\n",
    "    for match in matches:\n",
    "        # Get the keypoints indices for the current match\n",
    "        idx1 = match.queryIdx\n",
    "        idx2 = match.trainIdx\n",
    "        \n",
    "        # Get the coordinates of the keypoints\n",
    "        pt1 = tuple(map(int, keypoints1[idx1]))\n",
    "        pt2 = tuple(map(int, keypoints2[idx2]))\n",
    "\n",
    "        # Draw a line between the keypoints\n",
    "        r = random.randint(0, 255)\n",
    "        g = random.randint(0, 255)\n",
    "        b = random.randint(0, 255)\n",
    "        cv2.line(img_matches, pt1, (pt2[0] + img1.shape[1], pt2[1]), (b, g, r), 1)\n",
    "\n",
    "    # Display the image with the matching keypoints\n",
    "    cv2.imshow('Matches', img_matches)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TPS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.spatial.distance import cdist\n",
    "\n",
    "\n",
    "class TPS:\n",
    "    def fit(self, source, target, reg=1e-3):\n",
    "        '''\n",
    "            source -> n x 2 array of source points.\n",
    "            target -> n x 2 array of target points.\n",
    "            reg -> regularization coefficient.\n",
    "            return -> bending energy\n",
    "        '''\n",
    "        n = source.shape[0]\n",
    "        K = TPS.U(cdist(source, source, 'sqeuclidean'))\n",
    "        # regularaizing\n",
    "        K += reg * np.eye(K.shape[0])\n",
    "        P = np.concatenate((np.ones((n, 1)), source), axis=1)\n",
    "        L = np.vstack([np.hstack([K, P]),\n",
    "                       np.hstack([P.T, np.zeros((3, 3))])])\n",
    "        Y = np.concatenate((target, np.zeros((3, 2))), axis=0)\n",
    "        L_inv = np.linalg.inv(L)\n",
    "        L_inv_Y = np.matmul(L_inv, Y)\n",
    "        self.W = L_inv_Y\n",
    "        self.source = source\n",
    "        self.bending_energy = np.trace(np.matmul(np.matmul(self.W[:n, :].T, K), self.W[:n, :]))\n",
    "        return self.bending_energy\n",
    "\n",
    "    def transform(self, point):\n",
    "        '''\n",
    "            points -> 1 x 2 array representing (x, y).\n",
    "            return -> 1 x 2 array of transformed point.\n",
    "        '''\n",
    "        dist = TPS.U(cdist(point, self.source, 'sqeuclidean'))\n",
    "        tmp = np.array([[1, point[0, 0], point[0, 1]]])\n",
    "        new_point = np.matmul(np.hstack([dist, tmp]), self.W)\n",
    "        return new_point\n",
    "\n",
    "    def U(dist):\n",
    "        '''\n",
    "            dist -> matrix of squared euclidean distance\n",
    "                    between pairs.\n",
    "            return -> [d * log(d)] elementwise on dist.\n",
    "        '''\n",
    "        ret = np.zeros_like(dist)\n",
    "        mask = dist > 0\n",
    "        ret[mask] = dist[mask] * np.log(dist[mask])\n",
    "        return ret"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Shape Context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math, cv2\n",
    "import numpy as np\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "# import tps\n",
    "\n",
    "class Point:\n",
    "    def __init__(self, x, y):\n",
    "        self.x = float(x)\n",
    "        self.y = float(y)\n",
    "\n",
    "    def cart2logpolar(self):\n",
    "        '''\n",
    "            return (rho, theta)\n",
    "        '''\n",
    "        rho = math.sqrt(self.x * self.x + self.y * self.y)\n",
    "        theta = math.atan2(self.x, self.y)\n",
    "        return (math.log(rho), theta)\n",
    "\n",
    "    def dist2(self, other):\n",
    "        return (self.x - other.x)**2 + (self.y - other.y)**2\n",
    "\n",
    "class Shape:\n",
    "    def __init__(self, shape=None, img=None):\n",
    "        '''\n",
    "            shape -> 2d list of [[x1, y1], ...],\n",
    "                     default shape is canny edges\n",
    "            self.shape -> shape\n",
    "            self.shape_pts -> list of Point instead of lists.\n",
    "            self.shape_contexts -> list of [arrays -> shape_context]\n",
    "        '''\n",
    "        self.img = img\n",
    "        if shape is None:\n",
    "            shape = utils.canny_edge_shape(img)\n",
    "        self.shape = shape\n",
    "        self.shape_pts = []\n",
    "        for point in shape:\n",
    "            self.shape_pts.append(Point(point[0], point[1]))\n",
    "        self.shape_contexts = self.get_shape_contexts()\n",
    "\n",
    "    def get_shape_contexts(self, angular_bins=12, radious_bins=None):\n",
    "        '''\n",
    "            angular_bins -> number of bins for angle.\n",
    "            radious_bins -> number of bins for radious,\n",
    "                            default is maximum radious.\n",
    "            return -> list of shape context in image (bin array)\n",
    "        '''\n",
    "        # get maximum number of radious_bins\n",
    "        if radious_bins is None:\n",
    "            max_dist2 = 0\n",
    "            for i in range(len(self.shape_pts)):\n",
    "                for j in range(len(self.shape_pts)):\n",
    "                    max_dist2 = max(max_dist2, self.shape_pts[i].dist2(self.shape_pts[j]))\n",
    "            radious_bins = int(math.log(math.sqrt(max_dist2))) + 1\n",
    "        shape_contexts = [np.zeros((radious_bins, angular_bins), dtype=float) for _ in range(len(self.shape_pts))]\n",
    "        # compute bins\n",
    "        for i in range(len(self.shape_pts)):\n",
    "            for j in range(len(self.shape_pts)):\n",
    "                if i == j:\n",
    "                    continue\n",
    "                pt = Point(self.shape_pts[j].x - self.shape_pts[i].x,\n",
    "                           self.shape_pts[j].y - self.shape_pts[i].y)\n",
    "                r, theta = pt.cart2logpolar()\n",
    "                if r < 0:\n",
    "                    x = 0\n",
    "                else:\n",
    "                    x = int(r)\n",
    "                if theta == math.pi:\n",
    "                    y = angular_bins - 1\n",
    "                else:\n",
    "                    y = int(angular_bins * ((theta + math.pi) / (math.pi + math.pi)))\n",
    "                shape_contexts[i][x][y] += 1\n",
    "        return [shape_context.reshape((radious_bins * angular_bins)) for shape_context in shape_contexts]\n",
    "\n",
    "    def get_cost_matrix(self, Q, beta=.1, robust=False, dummy_cost=1):\n",
    "        '''\n",
    "            Q -> instance of Shape\n",
    "            beta -> coefficient of tangent_angle_dissimilarity,\n",
    "                    1-beta is coefficient of shape_context_cost\n",
    "            return -> (cost matrix for matching a points\n",
    "                      from shape_context1 to shape_context2,\n",
    "                      flag -> dummies added or not\n",
    "                              cif not -> 0\n",
    "                              if added to P -> -n\n",
    "                              if added to Q -> m)\n",
    "        '''\n",
    "        def normalize_histogram(hist, total):\n",
    "\n",
    "            for i in range(hist.shape[0]):\n",
    "                hist[i] /= float(total)\n",
    "            return hist\n",
    "\n",
    "        def shape_context_cost(nh1, nh2):\n",
    "            '''\n",
    "                nh1, nh2 -> normalized histogram\n",
    "                return cost of shape context of\n",
    "                two given shape context of the shape.\n",
    "            '''\n",
    "            cost = 0\n",
    "            if nh1.shape[0] > nh2.shape[0]:\n",
    "                nh1, nh2 = nh2, nh1\n",
    "            nh1 = np.hstack([nh1, np.zeros(nh2.shape[0] - nh1.shape[0])])\n",
    "            for k in range(nh1.shape[0]):\n",
    "                if nh1[k] + nh2[k] == 0:\n",
    "                    continue\n",
    "                cost += (nh1[k] - nh2[k])**2 / (nh1[k] + nh2[k])\n",
    "            return cost / 2.0\n",
    "\n",
    "        def tangent_angle_dissimilarity(p1, p2):\n",
    "            '''\n",
    "                p1 -> Point 1\n",
    "                p2 -> Point 2\n",
    "                return -> tangent angle dissimilarity of\n",
    "                          given two points\n",
    "            '''\n",
    "            theta1 = math.atan2(p1.x, p1.y)\n",
    "            theta2 = math.atan2(p2.x, p2.y)\n",
    "            return .5 * (1 - math.cos(theta1 - theta2))\n",
    "\n",
    "        if robust:\n",
    "            raise ValueError('robust=True not supported yet.')\n",
    "        n, m = len(self.shape_pts), len(Q.shape_pts)\n",
    "        flag = min(n, m) if (n != m) else 0\n",
    "        if flag and (n < m):\n",
    "            flag = -flag\n",
    "        mx = max(n, m)\n",
    "        C = np.zeros((mx, mx))\n",
    "        for i in range(mx):\n",
    "            if n <= i:\n",
    "                for j in range(mx):\n",
    "                    C[i, j] = dummy_cost\n",
    "            else:\n",
    "                p = self.shape_pts[i]\n",
    "                hist_p = normalize_histogram(self.shape_contexts[i], n-1)\n",
    "                for j in range(mx):\n",
    "                    if m <= j:\n",
    "                        C[i, j] = dummy_cost\n",
    "                    else:\n",
    "                        q = Q.shape_pts[j]\n",
    "                        hist_q = normalize_histogram(Q.shape_contexts[j], m-1)\n",
    "                        C[i, j] = (1-beta) * shape_context_cost(hist_p, hist_q)\\\n",
    "                            + beta * tangent_angle_dissimilarity(p, q)\n",
    "        return C, flag\n",
    "\n",
    "    def matching(self, Q):\n",
    "        '''\n",
    "            return -> two 2 x min(n, m) array.\n",
    "                      (Pshape, Qshape) point i\n",
    "                      from Pshape matched to\n",
    "                      point i from Qshape.\n",
    "        '''\n",
    "        cost_matrix, flag = self.get_cost_matrix(Q)\n",
    "        perm = linear_sum_assignment(cost_matrix)[1]\n",
    "        Pshape = np.array(self.shape)\n",
    "        Qshape = np.array(Q.shape)\n",
    "        # removing dummy matched.\n",
    "        if flag < 0:\n",
    "            mn = -flag\n",
    "            new_perm = perm[:mn]\n",
    "            Qshape = Qshape[new_perm]\n",
    "        elif flag > 0:\n",
    "            mn = flag\n",
    "            mask = perm < mn\n",
    "            new_perm = perm[mask]\n",
    "            Pshape = Pshape[mask]\n",
    "            Qshape = Qshape[new_perm]\n",
    "        return Pshape, Qshape\n",
    "\n",
    "    def estimate_transformation(source, target):\n",
    "        '''\n",
    "            source -> n x 2 array of source points.\n",
    "            target -> n x 2 array of source points.\n",
    "            return -> bending energy, TPS class for transformation\n",
    "        '''\n",
    "        T = TPS()\n",
    "        BE = T.fit(source, target)\n",
    "        return (BE, T)\n",
    "\n",
    "    def shape_context_distance(self, Q_transformed, T):\n",
    "        '''\n",
    "            Q_transformed -> transformed target shape.\n",
    "            T -> transformation function (TPS class)\n",
    "            return -> shape context distance\n",
    "        '''\n",
    "        n, m = len(self.shape), len(Q_transformed.shape)\n",
    "        cost_matrix = self.get_cost_matrix(Q_transformed)[0]\n",
    "        ret1, ret2 = 0.0, 0.0\n",
    "        for i in range(n):\n",
    "            mn = 1e20\n",
    "            for j in range(m):\n",
    "                mn = min(mn, cost_matrix[i, j])\n",
    "            ret1 += mn\n",
    "        for j in range(m):\n",
    "            mn = 1e20\n",
    "            for i in range(n):\n",
    "                mn = min(mn, cost_matrix[i, j])\n",
    "            ret2 += mn\n",
    "        return ret1 / n + ret2 / m\n",
    "\n",
    "    def appearance_cost(source, target_transformed, img_p, img_q, std=1, window_size=3):\n",
    "        '''\n",
    "            source -> n x 2 array [source shape].\n",
    "            target_transformed -> n x 2 array transformed target shape.\n",
    "                                  [point i matched with point i from source]\n",
    "            img_p -> source image.\n",
    "            img_q -> target image.\n",
    "            std -> scalar [standard deviation for guassian window].\n",
    "            window_size -> size of guassian window.\n",
    "            return -> appearance cost.\n",
    "        '''\n",
    "        def guassian_window(std, window_size):\n",
    "            '''\n",
    "                std -> scalar [standard deviation].\n",
    "                window_size -> size of guassian window.\n",
    "                return -> guassian window.\n",
    "            '''\n",
    "            window = np.zeros((window_size, window_size))\n",
    "            for x in range(-(window_size//2), window_size//2 + 1):\n",
    "                for y in range(-(window_size//2), window_size//2 + 1):\n",
    "                    window[x][y] = math.exp(-(x*x + y*y) / (2 * std * std)) / (2 * math.pi * std * std)\n",
    "            return window\n",
    "        ret = 0\n",
    "        G = guassian_window(std, window_size)\n",
    "        for i in range(source.shape[0]):\n",
    "            for x in range(-(window_size//2), window_size//2 + 1):\n",
    "                for y in range(-(window_size//2), window_size//2 + 1):\n",
    "                    px = min(int(x + source[i, 0]), img_p.shape[0]-1)\n",
    "                    py = min(int(y + source[i, 1]), img_p.shape[1]-1)\n",
    "                    Ip = int(img_p[px, py])\n",
    "                    qx = min(int(x + target_transformed[i, 0]), img_q.shape[0]-1)\n",
    "                    qy = min(int(y + target_transformed[i, 1]), img_q.shape[1]-1)\n",
    "                    Iq = int(img_q[qx, qy])\n",
    "                    ret += G[x + window_size//2, y + window_size//2] * (Ip - Iq)**2\n",
    "        return ret / source.shape[0]\n",
    "\n",
    "    def _distance(self, Q, w1, w2, w3, iterations=3):\n",
    "        '''\n",
    "            Q -> instance of Shape.\n",
    "            w1 -> weight of Appearance Cost.\n",
    "            w2 -> weight of Shape Contex distance.\n",
    "            w3 -> weigth of Transformation Cost.\n",
    "            iteration -> number of re-estimation of Transformation\n",
    "                         estimation.\n",
    "            return -> distance between two shapes.\n",
    "        '''\n",
    "        def transform_shape(Q, T):\n",
    "            '''\n",
    "                Q -> instance of Shape.\n",
    "                T -> instance of TPS.\n",
    "                return -> new Q which transformed with T.\n",
    "            '''\n",
    "            transformed_shape = []\n",
    "            for q in Q.shape:\n",
    "                Tq = T.transform(np.array(q).reshape((1, 2)))\n",
    "                transformed_shape.append([Tq[0, 0], Tq[0, 1]])\n",
    "            Q_transformed = Shape(transformed_shape, Q.img)\n",
    "            return Q_transformed\n",
    "\n",
    "        def transform_points(target_points, T):\n",
    "            '''\n",
    "                target_points -> n x 2 array of (x, y).\n",
    "                T -> instance of TPS.\n",
    "                return -> transform target_points with T.\n",
    "            '''\n",
    "            transformed_target = np.zeros_like(target_points)\n",
    "            for i in range(target_points.shape[0]):\n",
    "                new_pt = T.transform(target_points[i, :].reshape((1, 2)))\n",
    "                transformed_target[i, :] = new_pt\n",
    "            return transformed_target\n",
    "\n",
    "        for i in range(iterations):\n",
    "            source, target = self.matching(Q)\n",
    "            BE, T = Shape.estimate_transformation(source, target)\n",
    "            self = transform_shape(self, T)\n",
    "        Q_transformed = transform_shape(Q, T)\n",
    "        target_transformed = transform_points(target, T)\n",
    "        AC = Shape.appearance_cost(source, target_transformed, self.img, Q.img)\n",
    "        SC = self.shape_context_distance(Q, T)\n",
    "        return w1 * AC + w2 * SC + w3 * BE\n",
    "\n",
    "def distance(source_img, target_img, w1=1.6, w2=1, w3=.3):\n",
    "    P = Shape(img=source_img)\n",
    "    Q = Shape(img=target_img)\n",
    "    return P._distance(Q, w1, w2, w3)\n",
    "\n",
    "class utils:\n",
    "    def canny_edge_shape(img, max_samples=100, t1=100, t2=200):\n",
    "        '''\n",
    "            return -> list of sampled Points from edges\n",
    "                      founded by canny edge detector.\n",
    "        '''\n",
    "        edges = cv2.Canny(img, t1, t2)\n",
    "        x, y = np.where(edges != 0)\n",
    "        if x.shape[0] > max_samples:\n",
    "            idx = np.random.choice(x.shape[0], max_samples, replace=False)\n",
    "            x, y = x[idx], y[idx]\n",
    "        shape = []\n",
    "        for i in range(x.shape[0]):\n",
    "            shape.append([x[i], y[i]])\n",
    "        return shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
